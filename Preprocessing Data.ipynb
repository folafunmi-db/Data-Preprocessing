{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/folafunmi/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessingocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([[5.1, -2.9, 3.3], \n",
    "                       [-1.2, 7.8, -6.1], \n",
    "                       [3.9, 0.4, 2.1], \n",
    "                       [7.3, -9.9, -4.5]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of preprocessing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Binarization\n",
    "This process is used when we want to convert our numerical values into boolean values.\n",
    "Using 2.1 as the threshold, all values above it would become 1 and the rest becomes 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binarized data:\n",
      " [[1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data_binarized = preprocessing.Binarizer(threshold=2.1).transform(input_data)\n",
    "print(\"\\nBinarized data:\\n\", data_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mean Removal\n",
    "This is done so that each feature is centered around zero. It helps to remove bias from the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before:\n",
      "Mean =  [ 3.775 -1.15  -1.3  ]\n",
      "Standard Deviation =  [3.12039661 6.36651396 4.0620192 ]\n"
     ]
    }
   ],
   "source": [
    "#print mean and standard deviation\n",
    "print(\"\\nBefore:\")\n",
    "print(\"Mean = \", input_data.mean(axis = 0))\n",
    "print(\"Standard Deviation = \", input_data.std(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After:\n",
      "Mean =  [1.11022302e-16 0.00000000e+00 2.77555756e-17]\n",
      "Standard Deviation =  [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data_scaled = preprocessing.scale(input_data)\n",
    "print(\"\\nAfter:\")\n",
    "print(\"Mean = \", data_scaled.mean(axis = 0))\n",
    "print(\"Standard Deviation = \", data_scaled.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean is closer to zero and the standard deviation is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to bring the values of different features to within the same range, such that features with naturally large measurements wouldn't overwhelm others with smaller measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Data: \n",
      " [[ 5.1 -2.9  3.3]\n",
      " [-1.2  7.8 -6.1]\n",
      " [ 3.9  0.4  2.1]\n",
      " [ 7.3 -9.9 -4.5]]\n",
      "\n",
      "Min max scaled data: \n",
      " [[0.74117647 0.39548023 1.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.6        0.5819209  0.87234043]\n",
      " [1.         0.         0.17021277]]\n"
     ]
    }
   ],
   "source": [
    "#Min max scaling\n",
    "data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)\n",
    "\n",
    "print(\"\\nInput Data: \\n\", input_data)\n",
    "print(\"\\nMin max scaled data: \\n\", data_scaled_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each row is scaled such that the max value is 1 and all other values are relative to this value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modifies the values in the feature vector so that we can measure them on a common scale.\n",
    "\n",
    "Some common forms of normalization aim to modify the values so that they sum to 1: \n",
    "\n",
    ">L1 normalization, which refers to Least Absolute Deviation. This is such that the sum of absolute values is a row is 1.\n",
    "\n",
    ">L2 normalization which refers to least square makes sure the sum of squares is 1\n",
    "\n",
    "In general, L1 normalization technique is considered more robust than L2 normalization technique. L1 normalization technique is robust because it is resistant to outliers in the data. If we are solving a problem where outliers are important, then maybe L2 normalization becomes a better choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input data:\n",
      " [[ 5.1 -2.9  3.3]\n",
      " [-1.2  7.8 -6.1]\n",
      " [ 3.9  0.4  2.1]\n",
      " [ 7.3 -9.9 -4.5]]\n",
      "\n",
      "L1 normalized data:\n",
      " [[ 0.45132743 -0.25663717  0.2920354 ]\n",
      " [-0.0794702   0.51655629 -0.40397351]\n",
      " [ 0.609375    0.0625      0.328125  ]\n",
      " [ 0.33640553 -0.4562212  -0.20737327]]\n",
      "\n",
      "L2 normalized data:\n",
      " [[ 0.75765788 -0.43082507  0.49024922]\n",
      " [-0.12030718  0.78199664 -0.61156148]\n",
      " [ 0.87690281  0.08993875  0.47217844]\n",
      " [ 0.55734935 -0.75585734 -0.34357152]]\n"
     ]
    }
   ],
   "source": [
    "#Normalize data\n",
    "data_normalized_l1 = preprocessing.normalize(input_data, norm=\"l1\")\n",
    "data_normalized_l2 = preprocessing.normalize(input_data, norm=\"l2\")\n",
    "\n",
    "print(\"\\nInput data:\\n\", input_data)\n",
    "print(\"\\nL1 normalized data:\\n\", data_normalized_l1)\n",
    "print(\"\\nL2 normalized data:\\n\", data_normalized_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_normalized_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(data_normalized_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4513274336283185\n",
      "-0.2566371681415929\n",
      "0.29203539823008845\n",
      "-0.07947019867549669\n",
      "0.5165562913907285\n",
      "-0.40397350993377484\n",
      "0.609375\n",
      "0.0625\n",
      "0.328125\n",
      "0.33640552995391704\n",
      "-0.45622119815668205\n",
      "-0.20737327188940094\n"
     ]
    }
   ],
   "source": [
    "for a in range(len(data_normalized_l1)):\n",
    "    for val in data_normalized_l1[a]:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of absolute values of L1 normalized row 1:\n",
      "0.9999999999999998\n",
      "Sum of absolute values of L1 normalized row 2:\n",
      "1.0\n",
      "Sum of absolute values of L1 normalized row 3:\n",
      "1.0\n",
      "Sum of absolute values of L1 normalized row 4:\n",
      "1.0\n",
      "\n",
      "\n",
      "Sum of absolute values of L2 normalized row 1:\n",
      "0.9999999999999998\n",
      "Sum of absolute values of L2 normalized row 2:\n",
      "1.0\n",
      "Sum of absolute values of L2 normalized row 3:\n",
      "1.0\n",
      "Sum of absolute values of L2 normalized row 4:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for a in range(len(data_normalized_l1)):\n",
    "    abs_val = []\n",
    "    for val in data_normalized_l1[a]:\n",
    "        abs_val.append(abs(val))\n",
    "    print(f\"Sum of absolute values of L1 normalized row {a+1}:\")\n",
    "    print(sum(abs_val))\n",
    "    \n",
    "#fact\n",
    "print('\\n')\n",
    "for a in range(len(data_normalized_l2)):\n",
    "    abs_val = []\n",
    "    for val in data_normalized_l1[a]:\n",
    "        abs_val.append(abs(val))\n",
    "    print(f\"Sum of absolute values of L2 normalized row {a+1}:\")\n",
    "    print(sum(abs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
